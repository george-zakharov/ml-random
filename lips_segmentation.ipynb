{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lips_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "1spJ5CIHqPNM",
        "2GDVHD4uqYCP",
        "9LaihEKVr5aa"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNbSVS4AN0jei6TazGnRteG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/george-zakharov/ml-random/blob/master/lips_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1spJ5CIHqPNM",
        "colab_type": "text"
      },
      "source": [
        "# Load libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vyFE_PGb4Vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhAQkVrrb7GN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6575b2d3-08da-421a-8999-23301ccbd5c6"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1B6mbrOpiv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import data_table\n",
        "\n",
        "# from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "# from tensorflow.keras import utils\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "# from keras.models import Model\n",
        "# from keras.layers import Input, Conv2DTranspose, concatenate, Activation, MaxPooling2D, Conv2D, BatchNormalization\n",
        "# from keras import backend as K\n",
        "# from keras.optimizers import Adam\n",
        "# import matplotlib.pyplot as plt"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GDVHD4uqYCP",
        "colab_type": "text"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIFCUWvdqZdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGyFWwdqqejB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get raw data\n",
        "!cp '/content/drive/My Drive/Colab Notebooks/segmentation_test/lips.zip' lips.zip"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGJicx3bamuq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get pretrained values\n",
        "!cp '/content/drive/My Drive/Colab Notebooks/segmentation_test/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5' vgg16.h5"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT46Fd6zqgB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip it\n",
        "!unzip lips.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWgiDwtLqiLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Delete archive\n",
        "!rm lips.zip"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LaihEKVr5aa",
        "colab_type": "text"
      },
      "source": [
        "# Check the mappings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TerMvS52r9yG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mappings = pd.read_csv('set-lipstick-original/list.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kA-LG-VesL2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "050e6ef7-0ad7-45da-edae-43b6db1f937d"
      },
      "source": [
        "mappings.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>class</th>\n",
              "      <th>xmin</th>\n",
              "      <th>ymin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymax</th>\n",
              "      <th>mask</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image00000001.jpg</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>Lips</td>\n",
              "      <td>661</td>\n",
              "      <td>394</td>\n",
              "      <td>776</td>\n",
              "      <td>444</td>\n",
              "      <td>mask00000001.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image00000002.jpg</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>Lips</td>\n",
              "      <td>557</td>\n",
              "      <td>336</td>\n",
              "      <td>682</td>\n",
              "      <td>392</td>\n",
              "      <td>mask00000002.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image00000003.jpg</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>Lips</td>\n",
              "      <td>553</td>\n",
              "      <td>369</td>\n",
              "      <td>684</td>\n",
              "      <td>427</td>\n",
              "      <td>mask00000003.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image00000004.jpg</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>Lips</td>\n",
              "      <td>555</td>\n",
              "      <td>351</td>\n",
              "      <td>681</td>\n",
              "      <td>408</td>\n",
              "      <td>mask00000004.png</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image00000005.jpg</td>\n",
              "      <td>1280</td>\n",
              "      <td>720</td>\n",
              "      <td>Lips</td>\n",
              "      <td>555</td>\n",
              "      <td>351</td>\n",
              "      <td>680</td>\n",
              "      <td>407</td>\n",
              "      <td>mask00000005.png</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            filename  width  height class  ...  ymin  xmax  ymax              mask\n",
              "0  image00000001.jpg   1280     720  Lips  ...   394   776   444  mask00000001.png\n",
              "1  image00000002.jpg   1280     720  Lips  ...   336   682   392  mask00000002.png\n",
              "2  image00000003.jpg   1280     720  Lips  ...   369   684   427  mask00000003.png\n",
              "3  image00000004.jpg   1280     720  Lips  ...   351   681   408  mask00000004.png\n",
              "4  image00000005.jpg   1280     720  Lips  ...   351   680   407  mask00000005.png\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKsUOmlBw2x7",
        "colab_type": "text"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0PMA4U5aDU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Prepare dirs for files\n",
        "!mkdir DIR_X_TRAIN\n",
        "!mkdir DIR_X_TEST\n",
        "!mkdir DIR_Y_TRAIN\n",
        "!mkdir DIR_Y_TEST"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1c_55NeeRzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get first 5000 pics for training\n",
        "train_df = mappings.loc[0:4999]"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsmHDAWnghh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get test pics\n",
        "test_df = mappings.loc[5000:5099]"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzk1ZEtQfXbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy train pics\n",
        "for index, row in train_df.iterrows():\n",
        "    shutil.copy('/content/set-lipstick-original/720p/' + row['filename'], '/content/DIR_X_TRAIN/' + row['filename'])\n",
        "    shutil.copy('/content/set-lipstick-original/mask/' + row['mask'], '/content/DIR_Y_TRAIN/' + row['mask'])"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLAqaP1PiIys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy test pics\n",
        "for index, row in test_df.iterrows():\n",
        "    shutil.copy('/content/set-lipstick-original/720p/' + row['filename'], '/content/DIR_X_TEST/' + row['filename'])\n",
        "    shutil.copy('/content/set-lipstick-original/mask/' + row['mask'], '/content/DIR_Y_TEST/' + row['mask'])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW3HKb48iwnl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's drop source images\n",
        "!rm -rf /content/set-lipstick-original/"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6zedKdZhdnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all paths\n",
        "x_test_files = glob.glob('/content/DIR_X_TEST/*')\n",
        "x_train_files = glob.glob('/content/DIR_X_TRAIN/*')\n",
        "y_test_files = glob.glob('/content/DIR_Y_TEST/*')\n",
        "y_train_files = glob.glob('/content/DIR_Y_TRAIN/*')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak1XOBcjn6RZ",
        "colab_type": "text"
      },
      "source": [
        "# Create train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKOgZ7Hhn8pf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3c359dfa-5820-43a1-f94c-7c3fbbaf21d2"
      },
      "source": [
        "# Create x_train\n",
        "img = image.load_img(x_train_files[0], target_size=(352, 480))  \n",
        "x_train = image.img_to_array(img)\n",
        "x_train = np.expand_dims(x_train, axis=0)\n",
        "x_train.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 352, 480, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmCvyOuwn_U3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Enrich x_train\n",
        "for i in range(len(x_train_files)):\n",
        "    if i > 0 : \n",
        "        img = image.load_img(x_train_files[i], target_size=(352,480))\n",
        "        buf = image.img_to_array(img)\n",
        "        buf = np.expand_dims(buf, axis=0)\n",
        "        x_train = np.concatenate((x_train, buf), axis=0)\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DQV_M6hoiUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create ypic3_train\n",
        "img = image.load_img(y_test_files[0], target_size=(352,480))  \n",
        "ypic3_train = image.img_to_array(img)\n",
        "ypic3_train = np.expand_dims(ypic3_train, axis=0)\n",
        "ypic3_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOHX1A0ZokqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Enrich ypic3_train\n",
        "for i in range(len(y_test_files)):\n",
        "    if i > 0 : \n",
        "        img = image.load_img(y_test_files[i], target_size=(352,480))\n",
        "        buf = image.img_to_array(img)\n",
        "        buf = np.expand_dims(buf, axis=0)\n",
        "        ypic3_train = np.concatenate((ypic3_train, buf), axis=0)\n",
        "ypic3_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuvjO4zJo21w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get y_train\n",
        "y_train = np.zeros((367, 352, 480))\n",
        "\n",
        "for num in range(367):\n",
        "     for y in range(352):\n",
        "          for x in range(480):\n",
        "                cl = ypic3_train[num,y,x,0]\n",
        "                if ypic3_train[num,y,x,1] == cl and ypic3_train[num,y,x,2] == cl:\n",
        "                  y_train[num,y,x] = cl \n",
        "                else:\n",
        "                  print('ERROR')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emmuispbo504",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for num in range(367):\n",
        "     for y in range(352):\n",
        "          for x in range(480):\n",
        "              cl = y_train[num,y,x]\n",
        "              if cl == 6 or cl == 7 or cl == 9 or cl == 10:\n",
        "                 cl = 2\n",
        "              if cl == 8:    \n",
        "                 cl = 6\n",
        "              if cl == 11:\n",
        "                 cl = 7\n",
        "              y_train[num, y, x] = cl "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AROrK9XNo7jY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = utils.to_categorical(y_train, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhzKWfFmpAdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)\n",
        "\n",
        "\n",
        "def unet(num_classes = 8, input_shape= (352, 480, 3)):\n",
        "    img_input = Input(input_shape)\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv1')(img_input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', name='block1_conv2')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    block_1_out = Activation('relu')(x)\n",
        "\n",
        "    x = MaxPooling2D()(block_1_out)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv1')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', name='block2_conv2')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    block_2_out = Activation('relu')(x)\n",
        "\n",
        "    x = MaxPooling2D()(block_2_out)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv1')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv2')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', name='block3_conv3')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    block_3_out = Activation('relu')(x)\n",
        "\n",
        "    x = MaxPooling2D()(block_3_out)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv1')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv2')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block4_conv3')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    block_4_out = Activation('relu')(x)\n",
        "\n",
        "    x = MaxPooling2D()(block_4_out)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv1')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv2')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', name='block5_conv3')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "\n",
        "    # Load pretrained weights.\n",
        "    for_pretrained_weight = MaxPooling2D()(x)\n",
        "    vgg16 = Model(img_input, for_pretrained_weight)\n",
        "    vgg16.load_weights('drive/My Drive/Colab Notebooks/7.Сегментация и продвинутые операции со свёрткой/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', by_name=True)\n",
        "\n",
        "    # UP 1\n",
        "    x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = concatenate([x, block_4_out])\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # UP 2\n",
        "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = concatenate([x, block_3_out])\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # UP 3\n",
        "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = concatenate([x, block_2_out])\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # UP 4\n",
        "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = concatenate([x, block_1_out])\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(num_classes, (3, 3), activation='softmax', padding='same')(x)\n",
        "\n",
        "    model = Model(img_input, x)\n",
        "    model.compile(optimizer=Adam(),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=[dice_coef])\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}